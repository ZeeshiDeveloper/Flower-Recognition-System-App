{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c23834a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec38063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb4bd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23213 images belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b108442f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4242 images belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd48ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30cd3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64 , kernel_size=3 , activation='relu' , input_shape=[64,64,3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfdad454",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64 , kernel_size=3 , activation='relu' ))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 , strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b152e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c58f3d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f87380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b0ed327",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=23 , activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3151d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02567ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "726/726 [==============================] - 235s 323ms/step - loss: 2.6404 - accuracy: 0.2188 - val_loss: 2.5396 - val_accuracy: 0.2395\n",
      "Epoch 2/30\n",
      "726/726 [==============================] - 235s 323ms/step - loss: 2.4025 - accuracy: 0.2727 - val_loss: 2.3254 - val_accuracy: 0.3230\n",
      "Epoch 3/30\n",
      "726/726 [==============================] - 199s 274ms/step - loss: 2.2291 - accuracy: 0.2941 - val_loss: 2.1344 - val_accuracy: 0.3475\n",
      "Epoch 4/30\n",
      "726/726 [==============================] - 200s 276ms/step - loss: 2.0987 - accuracy: 0.3087 - val_loss: 1.9702 - val_accuracy: 0.3628\n",
      "Epoch 5/30\n",
      "726/726 [==============================] - 198s 273ms/step - loss: 2.0206 - accuracy: 0.3122 - val_loss: 1.9414 - val_accuracy: 0.3406\n",
      "Epoch 6/30\n",
      "726/726 [==============================] - 199s 274ms/step - loss: 1.9435 - accuracy: 0.3240 - val_loss: 1.8262 - val_accuracy: 0.3520\n",
      "Epoch 7/30\n",
      "726/726 [==============================] - 199s 275ms/step - loss: 1.8865 - accuracy: 0.3387 - val_loss: 1.9064 - val_accuracy: 0.3640\n",
      "Epoch 8/30\n",
      "726/726 [==============================] - 199s 274ms/step - loss: 1.8248 - accuracy: 0.3579 - val_loss: 1.9089 - val_accuracy: 0.3397\n",
      "Epoch 9/30\n",
      "726/726 [==============================] - 199s 274ms/step - loss: 1.7822 - accuracy: 0.3763 - val_loss: 1.7053 - val_accuracy: 0.4104\n",
      "Epoch 10/30\n",
      "726/726 [==============================] - 203s 280ms/step - loss: 1.7405 - accuracy: 0.3884 - val_loss: 1.6597 - val_accuracy: 0.4196\n",
      "Epoch 11/30\n",
      "726/726 [==============================] - 202s 278ms/step - loss: 1.7058 - accuracy: 0.4057 - val_loss: 1.6939 - val_accuracy: 0.4158\n",
      "Epoch 12/30\n",
      "726/726 [==============================] - 232s 320ms/step - loss: 1.6708 - accuracy: 0.4249 - val_loss: 1.6396 - val_accuracy: 0.4208\n",
      "Epoch 13/30\n",
      "726/726 [==============================] - 203s 279ms/step - loss: 1.6415 - accuracy: 0.4460 - val_loss: 1.6085 - val_accuracy: 0.4653\n",
      "Epoch 14/30\n",
      "726/726 [==============================] - 202s 278ms/step - loss: 1.6103 - accuracy: 0.4742 - val_loss: 1.5139 - val_accuracy: 0.5111\n",
      "Epoch 15/30\n",
      "726/726 [==============================] - 204s 281ms/step - loss: 1.5731 - accuracy: 0.4992 - val_loss: 1.5407 - val_accuracy: 0.5057\n",
      "Epoch 16/30\n",
      "726/726 [==============================] - 236s 325ms/step - loss: 1.5414 - accuracy: 0.5154 - val_loss: 1.5397 - val_accuracy: 0.5080\n",
      "Epoch 17/30\n",
      "726/726 [==============================] - 440s 607ms/step - loss: 1.5036 - accuracy: 0.5288 - val_loss: 1.4737 - val_accuracy: 0.5446\n",
      "Epoch 18/30\n",
      "726/726 [==============================] - 209s 288ms/step - loss: 1.4841 - accuracy: 0.5365 - val_loss: 1.4591 - val_accuracy: 0.5358\n",
      "Epoch 19/30\n",
      "726/726 [==============================] - 203s 279ms/step - loss: 1.4578 - accuracy: 0.5437 - val_loss: 1.4131 - val_accuracy: 0.5533\n",
      "Epoch 20/30\n",
      "726/726 [==============================] - 206s 284ms/step - loss: 1.4341 - accuracy: 0.5511 - val_loss: 1.4091 - val_accuracy: 0.5526\n",
      "Epoch 21/30\n",
      "726/726 [==============================] - 199s 274ms/step - loss: 1.4128 - accuracy: 0.5556 - val_loss: 1.3595 - val_accuracy: 0.5554\n",
      "Epoch 22/30\n",
      "726/726 [==============================] - 205s 282ms/step - loss: 1.3965 - accuracy: 0.5639 - val_loss: 1.3407 - val_accuracy: 0.5707\n",
      "Epoch 23/30\n",
      "726/726 [==============================] - 202s 279ms/step - loss: 1.3684 - accuracy: 0.5708 - val_loss: 1.3580 - val_accuracy: 0.5580\n",
      "Epoch 24/30\n",
      "726/726 [==============================] - 217s 299ms/step - loss: 1.3487 - accuracy: 0.5750 - val_loss: 1.2871 - val_accuracy: 0.5736\n",
      "Epoch 25/30\n",
      "697/726 [===========================>..] - ETA: 9s - loss: 1.3400 - accuracy: 0.5790 "
     ]
    }
   ],
   "source": [
    "cnn.fit(x = training_set , validation_data = test_set , epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "220fc161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 143ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Aster': 0,\n",
       " 'Bellflower': 1,\n",
       " 'Iris': 2,\n",
       " 'Lavender': 3,\n",
       " 'Lily': 4,\n",
       " 'Marigold': 5,\n",
       " 'Orchid': 6,\n",
       " 'Poppy': 7,\n",
       " 'airplane': 8,\n",
       " 'apple': 9,\n",
       " 'black_eyed_susan': 10,\n",
       " 'car': 11,\n",
       " 'cat': 12,\n",
       " 'daisy': 13,\n",
       " 'dandelion': 14,\n",
       " 'dog': 15,\n",
       " 'fruit': 16,\n",
       " 'motorbike': 17,\n",
       " 'person': 18,\n",
       " 'rose': 19,\n",
       " 'sunflower': 20,\n",
       " 'tulip': 21,\n",
       " 'water_lily': 22}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('Prediction/das.webp',target_size=(64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image,axis=0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c12e33d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0486778  0.01995941 0.05284692 0.0382424  0.05538775 0.07003854\n",
      "  0.08590579 0.08046304 0.02042519 0.01943046 0.03773413 0.03356024\n",
      "  0.02304955 0.04336585 0.04226495 0.02193452 0.02318351 0.03124623\n",
      "  0.0305454  0.03534765 0.06770802 0.07618597 0.04249658]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e47236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
